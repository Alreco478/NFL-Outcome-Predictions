{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alrec\\AppData\\Local\\Temp\\ipykernel_31084\\1573016920.py:3: DtypeWarning: Columns (17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    }
   ],
   "source": [
    "# Load dataset (update the path to your file)\n",
    "file_path = r\"C:\\Users\\alrec\\Desktop\\DAT Capstone\\combined_nfl_play_by_play_2003_2023.csv\"\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 5 rows:\n",
      "   play_id          game_id home_team away_team season_type  week posteam  \\\n",
      "0        1  2003_01_ARI_DET       DET       ARI         REG     1     NaN   \n",
      "1       35  2003_01_ARI_DET       DET       ARI         REG     1     DET   \n",
      "2       57  2003_01_ARI_DET       DET       ARI         REG     1     DET   \n",
      "3       78  2003_01_ARI_DET       DET       ARI         REG     1     DET   \n",
      "4       99  2003_01_ARI_DET       DET       ARI         REG     1     DET   \n",
      "\n",
      "  posteam_type side_of_field  yardline_100  ... total_line    surface  temp  \\\n",
      "0          NaN           NaN           NaN  ...       39.0  fieldturf   NaN   \n",
      "1         home           ARI          30.0  ...       39.0  fieldturf   NaN   \n",
      "2         home           DET          70.0  ...       39.0  fieldturf   NaN   \n",
      "3         home           DET          61.0  ...       39.0  fieldturf   NaN   \n",
      "4         home           DET          59.0  ...       39.0  fieldturf   NaN   \n",
      "\n",
      "   wind pass rush  first_down special  play    qb_epa  \n",
      "0   NaN    0    0         NaN       0     0  0.000000  \n",
      "1   NaN    0    0         0.0       1     0  0.676785  \n",
      "2   NaN    1    0         0.0       0     1  0.762116  \n",
      "3   NaN    0    1         1.0       0     1 -0.172637  \n",
      "4   NaN    1    0         0.0       0     1  0.740568  \n",
      "\n",
      "[5 rows x 105 columns]\n",
      "Number of Rows: 997412\n",
      "Number of Columns: 105\n",
      "\n",
      "Wrote number of missing values per column to nan_count.csv\n",
      "\n",
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "# Display first few rows of the dataframe\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df.head())\n",
    "\n",
    "# Display number of rows and columns\n",
    "num_rows, num_columns = df.shape\n",
    "print(f\"Number of Rows: {num_rows}\")\n",
    "print(f\"Number of Columns: {num_columns}\")\n",
    "columns = pd.DataFrame(df.columns, columns=[\"Column Name\"])\n",
    "\n",
    "'''\n",
    "# Check for missing values\n",
    "missing_values = df.isnull().sum().sort_values(ascending=False)\n",
    "missing_df = pd.DataFrame({'Column': missing_values.index, 'NA_Count': missing_values.values})\n",
    "output_path = r\"C:/Users/alrec/Desktop/DAT Capstone/nan_count.csv\"\n",
    "\n",
    "# Save missing value count to nan_count.csv\n",
    "missing_df.to_csv(output_path, index=False)\n",
    "print(\"\\nWrote number of missing values per column to nan_count.csv\")\n",
    "'''\n",
    "\n",
    "# Check for duplicate rows\n",
    "print(\"\\nNumber of duplicate rows:\", df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wrote number of missing values per column to nan_count_filtered.csv\n",
      "Number of rows:  926838\n"
     ]
    }
   ],
   "source": [
    "# drop st_play_type column\n",
    "df_trimmed = df.drop(columns=['st_play_type'])\n",
    "\n",
    "# filter out entries that aren't a play\n",
    "filter_values = [\"GAME\", \"END QUARTER 1\", \"END QUARTER 2\", \"END QUARTER 3\", \"END GAME\"]\n",
    "df_filtered = df_trimmed[~df_trimmed['desc'].isin(filter_values)]\n",
    "df_filtered = df_filtered[~df_filtered['desc'].str.contains(r'Timeout', na=False)]\n",
    "\n",
    "'''\n",
    "# Check for missing values\n",
    "missing_values = df_filtered.isnull().sum().sort_values(ascending=False)\n",
    "missing_df = pd.DataFrame({'Column': missing_values.index, 'NA_Count': missing_values.values})\n",
    "\n",
    "# Save missing value count to nan_count_filtered.csv\n",
    "output_path = r\"C:/Users/alrec/Desktop/DAT Capstone/nan_count_filtered.csv\"\n",
    "missing_df.to_csv(output_path, index=False)\n",
    "print(\"\\nWrote number of missing values per column to nan_count_filtered.csv\")\n",
    "'''\n",
    "\n",
    "print(\"Number of rows: \", len(df_filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan 'made' 'missed' 'blocked']\n",
      "[nan 'good' 'blocked' 'failed' 'aborted']\n",
      "[nan 'success' 'failure']\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'C:/Users/alrec/Desktop/DAT Capstone/df_encoded.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m df_encoded \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mget_dummies(df_filtered, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfield_goal_result\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mextra_point_result\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtwo_point_conv_result\u001b[39m\u001b[38;5;124m'\u001b[39m], drop_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      8\u001b[0m output_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/alrec/Desktop/DAT Capstone/df_encoded.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 9\u001b[0m \u001b[43mdf_encoded\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\generic.py:3967\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3956\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   3958\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3959\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3960\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3964\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3965\u001b[0m )\n\u001b[1;32m-> 3967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3969\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3970\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3972\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3973\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3974\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3975\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3976\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3977\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3978\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3979\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3981\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3982\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3983\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3984\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\formats\\format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m    993\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    995\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m    996\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m    997\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1013\u001b[0m )\n\u001b[1;32m-> 1014\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\formats\\csvs.py:251\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    261\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    262\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    267\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    268\u001b[0m     )\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'C:/Users/alrec/Desktop/DAT Capstone/df_encoded.csv'"
     ]
    }
   ],
   "source": [
    "print(df_filtered['field_goal_result'].unique())\n",
    "print(df_filtered['extra_point_result'].unique())\n",
    "print(df_filtered['two_point_conv_result'].unique())\n",
    "\n",
    "# One-hot encoding for the specified columns\n",
    "df_encoded = pd.get_dummies(df_filtered, columns=['field_goal_result', 'extra_point_result', 'two_point_conv_result'], drop_first=True)\n",
    "\n",
    "# Output new df to df_encoded.csv\n",
    "'''\n",
    "output_path = r\"C:/Users/alrec/Desktop/DAT Capstone/df_encoded.csv\"\n",
    "df_encoded.to_csv(output_path, index=False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate data by game and team\n",
    "aggregated = df_encoded.groupby(['game_id', 'posteam']).agg({\n",
    "    'yards_gained': 'sum',\n",
    "    'receiving_yards': 'sum',\n",
    "    'rushing_yards': 'sum',\n",
    "    'return_yards': 'sum',\n",
    "    'incomplete_pass': 'sum',\n",
    "    'complete_pass': 'sum',\n",
    "    'interception': 'sum',\n",
    "    'pass_attempt': 'sum',\n",
    "    'rush_attempt': 'sum',\n",
    "    'touchdown': 'sum',\n",
    "    'pass_touchdown': 'sum',\n",
    "    'rush_touchdown': 'sum',\n",
    "    'return_touchdown': 'sum',\n",
    "    'first_down': 'sum',\n",
    "    'play': 'sum',\n",
    "    'sack': 'sum',\n",
    "    'fumble': 'sum',\n",
    "    'fumble_lost': 'sum',\n",
    "    'field_goal_result_made': 'sum',\n",
    "    'field_goal_result_missed': 'sum',\n",
    "    'extra_point_result_good': 'sum',\n",
    "    'extra_point_result_failed': 'sum',\n",
    "    'safety': 'sum',\n",
    "    'total_home_epa': 'max',\n",
    "    'total_away_epa': 'max',\n",
    "    'total_home_score': 'max',\n",
    "    'total_away_score': 'max',\n",
    "    'total': 'max'\n",
    "}).reset_index()\n",
    "\n",
    "# Make a copy of the dataframe but swap the teams to calculate defensive stats\n",
    "df_defense = df_encoded.copy()\n",
    "\n",
    "# Swap posteam with the opposing team to get the defensive stats for the right team\n",
    "df_defense['posteam'] = df_defense.apply(\n",
    "    lambda row: row['home_team'] if row['posteam'] == row['away_team'] else row['away_team'], axis=1)\n",
    "\n",
    "# Aggregate the data by game and posteam (now representing the defensive side)\n",
    "aggregated_defense = df_defense.groupby(['game_id', 'posteam']).agg({\n",
    "    'yards_gained': 'sum',\n",
    "    'first_down': 'sum',\n",
    "    'touchdown': 'sum',\n",
    "    'play': 'sum',\n",
    "    'interception': 'sum',\n",
    "    'fumble_forced': 'sum',\n",
    "    'fumble_lost': 'sum',\n",
    "    'total_home_score': 'max',\n",
    "    'total_away_score': 'max',\n",
    "}).reset_index()\n",
    "\n",
    "# Rename columns to make it clear these are defensive stats\n",
    "aggregated_defense.rename(columns={\n",
    "    'yards_gained': 'yards_allowed',\n",
    "    'first_down': 'first_down_allowed',\n",
    "    'touchdown': 'touchdowns_allowed',\n",
    "    'interception': 'turnovers_gained',\n",
    "    'fumble_forced': 'fumbles_forced',\n",
    "    'fumble_lost': 'fumbles_recovered',\n",
    "}, inplace=True)\n",
    "\n",
    "# Now merge this defensive aggregated dataframe back with the original offensive one\n",
    "aggregated = aggregated.merge(aggregated_defense, on=['game_id', 'posteam'], suffixes=('', '_defense'))\n",
    "\n",
    "# Add offensive calculated stats: yards per play, points per play, first down rate, and number of turnovers (lost)\n",
    "aggregated['yards_per_play_offense'] = aggregated['yards_gained'] / aggregated['play']\n",
    "aggregated['points_per_play_offense'] = (aggregated['total_home_score'] + aggregated['total_away_score']) / aggregated['play']\n",
    "aggregated['first_down_rate_offense'] = aggregated['first_down'] / aggregated['play']\n",
    "aggregated['turnovers_lost'] = aggregated['interception'] + aggregated['fumble_lost']\n",
    "\n",
    "# Add defensive calculated stats: yards per play allowed, points per play allowed, first down rate allowed, and turnovers gained\n",
    "aggregated['yards_per_play_allowed'] = aggregated['yards_allowed'] / aggregated['play_defense']\n",
    "aggregated['points_per_play_allowed'] = (aggregated['total_home_score_defense'] + aggregated['total_away_score_defense']) / aggregated['play_defense']\n",
    "aggregated['first_down_rate_allowed'] = aggregated['first_down_allowed'] / aggregated['play_defense']\n",
    "\n",
    "# Turnovers gained by defense (interceptions + fumbles recovered)\n",
    "aggregated['turnovers_gained'] = aggregated['turnovers_gained'] + aggregated['fumbles_recovered']\n",
    "\n",
    "# add special teams calculated stats: fg percentage, xp percentage\n",
    "aggregated['fg_percentage'] = aggregated['field_goal_result_made'] / (\n",
    "        aggregated['field_goal_result_made'] + aggregated['field_goal_result_missed'])\n",
    "aggregated['xp_percentage'] = aggregated['extra_point_result_good'] / (\n",
    "        aggregated['extra_point_result_good'] + aggregated['extra_point_result_failed'])\n",
    "\n",
    "# Add turnover differential\n",
    "aggregated['turnover_differential'] = aggregated['turnovers_gained'] - aggregated['turnovers_lost']\n",
    "\n",
    "\n",
    "output_path = r\"C:/Users/alrec/Desktop/DAT Capstone/df_transform.csv\"\n",
    "aggregated.to_csv(output_path, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
