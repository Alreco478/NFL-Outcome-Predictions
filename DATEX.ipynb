{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alrec\\AppData\\Local\\Temp\\ipykernel_47364\\1573016920.py:3: DtypeWarning: Columns (17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    }
   ],
   "source": [
    "# Load dataset (update the path to your file)\n",
    "file_path = r\"C:\\Users\\alrec\\Desktop\\DAT Capstone\\combined_nfl_play_by_play_2003_2023.csv\"\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 5 rows:\n",
      "   play_id          game_id home_team away_team season_type  week posteam  \\\n",
      "0        1  2003_01_ARI_DET       DET       ARI         REG     1     NaN   \n",
      "1       35  2003_01_ARI_DET       DET       ARI         REG     1     DET   \n",
      "2       57  2003_01_ARI_DET       DET       ARI         REG     1     DET   \n",
      "3       78  2003_01_ARI_DET       DET       ARI         REG     1     DET   \n",
      "4       99  2003_01_ARI_DET       DET       ARI         REG     1     DET   \n",
      "\n",
      "  posteam_type side_of_field  yardline_100  ... total_line    surface  temp  \\\n",
      "0          NaN           NaN           NaN  ...       39.0  fieldturf   NaN   \n",
      "1         home           ARI          30.0  ...       39.0  fieldturf   NaN   \n",
      "2         home           DET          70.0  ...       39.0  fieldturf   NaN   \n",
      "3         home           DET          61.0  ...       39.0  fieldturf   NaN   \n",
      "4         home           DET          59.0  ...       39.0  fieldturf   NaN   \n",
      "\n",
      "   wind pass rush  first_down special  play    qb_epa  \n",
      "0   NaN    0    0         NaN       0     0  0.000000  \n",
      "1   NaN    0    0         0.0       1     0  0.676785  \n",
      "2   NaN    1    0         0.0       0     1  0.762116  \n",
      "3   NaN    0    1         1.0       0     1 -0.172637  \n",
      "4   NaN    1    0         0.0       0     1  0.740568  \n",
      "\n",
      "[5 rows x 105 columns]\n",
      "Number of Rows: 997412\n",
      "Number of Columns: 105\n",
      "\n",
      "Wrote number of missing values per column to nan_count.csv\n",
      "\n",
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "# Display first few rows of the dataframe\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df.head())\n",
    "\n",
    "# Display number of rows and columns\n",
    "num_rows, num_columns = df.shape\n",
    "print(f\"Number of Rows: {num_rows}\")\n",
    "print(f\"Number of Columns: {num_columns}\")\n",
    "columns = pd.DataFrame(df.columns, columns=[\"Column Name\"])\n",
    "\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = df.isnull().sum().sort_values(ascending=False)\n",
    "missing_df = pd.DataFrame({'Column': missing_values.index, 'NA_Count': missing_values.values})\n",
    "output_path = r\"C:/Users/alrec/Desktop/DAT Capstone/nan_count.csv\"\n",
    "\n",
    "# Save missing value count to nan_count.csv\n",
    "missing_df.to_csv(output_path, index=False)\n",
    "print(\"\\nWrote number of missing values per column to nan_count.csv\")\n",
    "\n",
    "\n",
    "# Check for duplicate rows\n",
    "print(\"\\nNumber of duplicate rows:\", df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wrote number of missing values per column to nan_count_filtered.csv\n",
      "Number of rows:  926838\n"
     ]
    }
   ],
   "source": [
    "# drop st_play_type column\n",
    "df_trimmed = df.drop(columns=['st_play_type'])\n",
    "\n",
    "# filter out entries that aren't a play\n",
    "filter_values = [\"GAME\", \"END QUARTER 1\", \"END QUARTER 2\", \"END QUARTER 3\", \"END GAME\"]\n",
    "df_filtered = df_trimmed[~df_trimmed['desc'].isin(filter_values)]\n",
    "df_filtered = df_filtered[~df_filtered['desc'].str.contains(r'Timeout', na=False)]\n",
    "\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = df_filtered.isnull().sum().sort_values(ascending=False)\n",
    "missing_df = pd.DataFrame({'Column': missing_values.index, 'NA_Count': missing_values.values})\n",
    "\n",
    "# Save missing value count to nan_count_filtered.csv\n",
    "output_path = r\"C:/Users/alrec/Desktop/DAT Capstone/nan_count_filtered.csv\"\n",
    "missing_df.to_csv(output_path, index=False)\n",
    "print(\"\\nWrote number of missing values per column to nan_count_filtered.csv\")\n",
    "\n",
    "\n",
    "print(\"Number of rows: \", len(df_filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote df_encoded to csv\n"
     ]
    }
   ],
   "source": [
    "# One-hot encoding for the specified columns\n",
    "df_encoded = pd.get_dummies(df_filtered, columns=['field_goal_result', 'extra_point_result', 'two_point_conv_result'], drop_first=True)\n",
    "\n",
    "# Output new df to df_encoded.csv\n",
    "output_path = r\"C:/Users/alrec/Desktop/DAT Capstone/df_encoded.csv\"\n",
    "df_encoded.to_csv(output_path, index=False)\n",
    "print(\"Wrote df_encoded to csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate data by game and team\n",
    "aggregated = df_encoded.groupby(['game_id', 'posteam']).agg({\n",
    "    'yards_gained': 'sum',\n",
    "    'receiving_yards': 'sum',\n",
    "    'rushing_yards': 'sum',\n",
    "    'return_yards': 'sum',\n",
    "    'incomplete_pass': 'sum',\n",
    "    'complete_pass': 'sum',\n",
    "    'interception': 'sum',\n",
    "    'pass_attempt': 'sum',\n",
    "    'rush_attempt': 'sum',\n",
    "    'touchdown': 'sum',\n",
    "    'pass_touchdown': 'sum',\n",
    "    'rush_touchdown': 'sum',\n",
    "    'return_touchdown': 'sum',\n",
    "    'first_down': 'sum',\n",
    "    'play': 'sum',\n",
    "    'sack': 'sum',\n",
    "    'fumble': 'sum',\n",
    "    'fumble_lost': 'sum',\n",
    "    'field_goal_result_made': 'sum',\n",
    "    'field_goal_result_missed': 'sum',\n",
    "    'extra_point_result_good': 'sum',\n",
    "    'extra_point_result_failed': 'sum',\n",
    "    'safety': 'sum',\n",
    "    'total_home_epa': 'max',\n",
    "    'total_away_epa': 'max',\n",
    "    'total_home_score': 'max',\n",
    "    'total_away_score': 'max',\n",
    "    'total': 'max'\n",
    "}).reset_index()\n",
    "\n",
    "# Make a copy of the dataframe but swap the teams to calculate defensive stats\n",
    "df_defense = df_encoded.copy()\n",
    "\n",
    "# Swap posteam with the opposing team to get the defensive stats for the right team\n",
    "df_defense['posteam'] = df_defense.apply(\n",
    "    lambda row: row['home_team'] if row['posteam'] == row['away_team'] else row['away_team'], axis=1)\n",
    "\n",
    "# Aggregate the data by game and posteam (now representing the defensive side)\n",
    "aggregated_defense = df_defense.groupby(['game_id', 'posteam']).agg({\n",
    "    'yards_gained': 'sum',\n",
    "    'first_down': 'sum',\n",
    "    'touchdown': 'sum',\n",
    "    'play': 'sum',\n",
    "    'interception': 'sum',\n",
    "    'fumble_forced': 'sum',\n",
    "    'fumble_lost': 'sum',\n",
    "    'total_home_score': 'max',\n",
    "    'total_away_score': 'max',\n",
    "}).reset_index()\n",
    "\n",
    "# Rename columns to make it clear these are defensive stats\n",
    "aggregated_defense.rename(columns={\n",
    "    'yards_gained': 'yards_allowed',\n",
    "    'first_down': 'first_down_allowed',\n",
    "    'touchdown': 'touchdowns_allowed',\n",
    "    'interception': 'turnovers_gained',\n",
    "    'fumble_forced': 'fumbles_forced',\n",
    "    'fumble_lost': 'fumbles_recovered',\n",
    "}, inplace=True)\n",
    "\n",
    "# Now merge this defensive aggregated dataframe back with the original offensive one\n",
    "aggregated = aggregated.merge(aggregated_defense, on=['game_id', 'posteam'], suffixes=('', '_defense'))\n",
    "\n",
    "# Add offensive calculated stats: yards per play, points per play, first down rate, and number of turnovers (lost)\n",
    "aggregated['yards_per_play_offense'] = aggregated['yards_gained'] / aggregated['play']\n",
    "aggregated['points_per_play_offense'] = (aggregated['total_home_score'] + aggregated['total_away_score']) / aggregated['play']\n",
    "aggregated['first_down_rate_offense'] = aggregated['first_down'] / aggregated['play']\n",
    "aggregated['turnovers_lost'] = aggregated['interception'] + aggregated['fumble_lost']\n",
    "\n",
    "# Add defensive calculated stats: yards per play allowed, points per play allowed, first down rate allowed, and turnovers gained\n",
    "aggregated['yards_per_play_allowed'] = aggregated['yards_allowed'] / aggregated['play_defense']\n",
    "aggregated['points_per_play_allowed'] = (aggregated['total_home_score_defense'] + aggregated['total_away_score_defense']) / aggregated['play_defense']\n",
    "aggregated['first_down_rate_allowed'] = aggregated['first_down_allowed'] / aggregated['play_defense']\n",
    "\n",
    "# Turnovers gained by defense (interceptions + fumbles recovered)\n",
    "aggregated['turnovers_gained'] = aggregated['turnovers_gained'] + aggregated['fumbles_recovered']\n",
    "\n",
    "# add special teams calculated stats: fg percentage, xp percentage\n",
    "aggregated['fg_percentage'] = aggregated['field_goal_result_made'] / (\n",
    "        aggregated['field_goal_result_made'] + aggregated['field_goal_result_missed'])\n",
    "aggregated['xp_percentage'] = aggregated['extra_point_result_good'] / (\n",
    "        aggregated['extra_point_result_good'] + aggregated['extra_point_result_failed'])\n",
    "\n",
    "# Add turnover differential\n",
    "aggregated['turnover_differential'] = aggregated['turnovers_gained'] - aggregated['turnovers_lost']\n",
    "\n",
    "\n",
    "output_path = r\"C:/Users/alrec/Desktop/DAT Capstone/df_transform.csv\"\n",
    "aggregated.to_csv(output_path, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
